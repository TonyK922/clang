嵌入式是一门交叉学科.  

嵌入式开发, 一般涉及芯片, 硬件电路, 操作系统, 软件工程, 通信协议, 产品测试等各个领域的知识, 对嵌入式开发者的技能栈要求更高. 

对于嵌入式开发者来说, 当一个产品出现问题时, 可能还要从芯片配置, 硬件电路, 操作系统, 调试环境等角度去分析问题到底出在哪里. 

这就要求嵌入式工程师最好具备电子电路, 操作系统, 编程语言, 软件工程等各方面的知识和技能. 

嵌入式开发
- 编程特点
	- 健壮性
	- 安全性
	- 实时性
- 各种各样的bug
	- 业务逻辑
	- 语言语法
	- 编译器
	- 操作系统
	- 硬件电路
	- 芯片

像系统一样思考
- 多任务 可重入函数  临界区 系统调用 中断原理
- 进程栈, 中断栈
- 存储器映射, 重映射
- DMA, cache, register
- 内存管理单元: MMU
- IO端口与IO内存
- 位运算, 位域

# 多任务的裸机实现

多任务编程

为什么要多任务?
- 系统越来越复杂
- 多任务设计, 可简化软件设计

随着嵌入式产品功能越来越多, 系统越来越复杂, 我们也要不断地提升相关的理论, 技术和开发方法. 

通过模块化设计可以将一个复杂的系统划分成不同的模块, 划分成不同的任务去实现, 这种模块化设计方法和多任务编程思想不仅可以简化软件设计, 而且会让后续的升级和维护更加方便. 

哪怕在一个资源受限的嵌入式裸机环境下, 一个业务复杂的软件如果尝试使用多任务编程思想去实现, 编程的难度也会大大降低, 后期软件的升级和维护也会更加方便. 

## 多任务的模拟实现

假设我们想基于C51单片机平台实现一个温度控制系统, 对塑料大棚进行温度控制: 用户可以通过按键设置预定温度, 系统会通过温度传感器获取当前温度, 并通过数码管显示. 当温度低于我们的设定温度时, 系统会启动加热装置提高温度. 

通过模块化设计方法, 我们可以将温度控制系统划分为不同的模块: 按键扫描, 数码管显示, 温度获取, 温度加热. 

通过多任务编程思想, 我们可以创建4个不同的任务来实现: 按键扫描任务, 数码管显示任务, 温度获取任务, 温度加热任务, 如图所示. 
- ![](assets/Pasted%20image%2020230511235848.png)

问题

多任务带来的时间问题
- 每个任务的执行间隔
- 每个任务的执行时间

任务的分类
- 有些任务需要频繁运行: 数码管显示, 按键扫描
- 有些任务不需要频繁运行: 温度传感器, 温度设置

循环+前后台

在裸机环境下, 我们可以在main()函数中设计一个大循环来模拟多任务的实现. 
```c
#include<stdio.h>
void delay(int ms)
{
    for(int i=0; i<5000000; i++)
        for(int j=0; j<ms; j++)
            ; 
}
int task_key_scan(void)
{
    int key_value; 
    printf("keyboard scan...\n"); 
    return key_value; 
}
void task_led_show(void)
{
    printf("led show...\n"); 
}
void task_temperature_get(void)
{
    printf("DB18S20 init...\n"); 
}
void task_temperature_set(void)
{
    printf("set temperature...\n"); 
}
int main(void)
{
    while(1)
    {
        task_temperature_get(); 
        delay(100); 
        task_led_show(); 
        delay(100); 
        task_key_scan(); 
        delay(100); 
        task_temperature_set(); 
        delay(100); 
        printf("\n\n"); 
    }
    return 0; 
}
```

## 改变任务的执行频率

通过上面的程序设计, 我们可以让这4个任务依次循环运行, 但还是会存在一些问题: 每个任务的执行频率是不一样的. 

如数码管显示, 按键扫描任务需要频繁运行, 否则用户的按键事件就可能检测不到; 数码管的动态刷新频率低了, 数码管的显示可能就会闪烁. 而有些任务不需要频繁运行, 如温度的获取和设置, 温度的变化是非常缓慢的, 我们不需要每秒都去获取数据, 每1分钟, 甚至每5分钟获取一次温度数据都是可以接受的. 

因此我们需要对上面的程序进行改进, 改变不同任务的执行频率. 

```c
#include<stdio.h>

unsigned int count; 
void count_add(void)
{
    for(int i=0; i<5000000; i++)
        ; 
    count++; 
}
int task_key_scan(void)
{
    int key_value; 
    printf("keyboard scan...\n"); 
    return key_value; 
}
void task_led_show(void)
{
    printf("led show...\n"); 
}
void task_temperature_get(void)
{
    printf("DB18S20 init...\n"); 
}
void task_temperature_set(void)
{
    printf("set temperature...\n"); 
}
int main(void)
{
    while(1)
    {
        count_add(); 
        if(count%1000==0)
            task_temperature_get(); 
  
        if(count%100==0)    
            task_led_show(); 

        if(count%200==0)
            task_key_scan(); 

        if(count%2000==0)
            task_temperature_set(); 
    } 
    return 0; 
}
```

为了让每个任务按照不同的频率运行, 我们在main()函数的大循环中添加了一个计数器函数: count_add(). 通过这种设计, 每个任务运行的频率就可以改变了: 按键扫描或数码管显示的任务, 需要频繁运行, 我们可以将计数值设置得小一点; 温度获取, 温度加热的任务不需要频繁运行, 我们可以将计数值设置得大一点. 

在实际的嵌入式系统中, 计数器函数count_add()一般使用一个定时器或时钟中断函数来代替, 这样我们就不需要在main()函数的大循环中显式调用计数器函数了. 定时器到期或时钟中断来了, 当前正在运行的程序会被打断, CPU会自动跳到中断函数执行, 然后在中断函数中完成对计数器的累加操作. 
```c
void rtc_interrupt(void)
{
    count++; 
}
```

## 改变任务的执行时间

通过上面的设计, 我们可以改变不同任务的执行频率, 但还是不够完美, 在实际运行时仍旧会遇到一些问题, 如没有考虑每个任务执行时间的长短. 

例如按键扫描任务需要每100ms执行一次, 如果其他任务的运行时间比较长, 如温度加热任务运行一次可能需要500ms, 那么就会影响按键扫描任务的运行. 

为了解决这个问题, 我们可以尝试将运行时间耗时较长的任务分解为多个子任务, 分阶段执行, 通过`状态机`来实现. 

多任务带来的时间问题
- 每个任务的执行时间

解决方案
- 合理安排每个任务的运行时间

长延时任务的分解
- 解决方案
	- 将运行时间较长的任务分解为多个子任务
		- ![](assets/Pasted%20image%2020230512000829.png)
	- 多任务的状态机实现
		- ![](assets/Pasted%20image%2020230512001801.png)
	- 有限状态机
		- ![](assets/Pasted%20image%2020230512001904.png)

对温度控制系统进行改进: 
- 对于运行时间较长的任务, 如数码管显示, 我们可以将其分解为不同的子任务: 每次只刷新一个数码管, 通过状态机的有限个状态来标记每次刷新的情况. 
- 对于按键扫描任务也是如此, 按键消抖延时会占用很长时间, 我们也可以将按键任务分解为按键按下, 按键消抖, 按键释放3个子任务, 然后使用状态机记录不同的状态, 分阶段执行, 就可以解决任务运行时间过长的问题. 

```c
#include<stdio.h>

unsigned int count; 
void rtc_interrupt(void)
{
	for(int i=0; i<500000; i++)
		; 		
	count++; 
}
void task1(void)
{
	static int task1_state=0; 
	switch(task1_state){
		case 0: 
			task1_state++; printf("task1: step 0\n"); break; 
		case 1: 
			task1_state++; printf("task1: step 1\n"); break; 
		case 2: 
			task1_state++; printf("task1: step 2\n"); break; 
		case 3: 
			task1_state++; printf("task1: step 3\n"); break; 
		default:  
			printf("task1:  undefined step\n"); break; 
	}
}
void task2(void)
{
	static int task2_state=0; 
	switch(task2_state){
		case 0: 
			task2_state++; printf("task2: step 0\n"); break; 
		case 1: 
			task2_state++; printf("task2: step 1\n"); break; 
		case 2: 
			task2_state++; printf("task2: step 2\n"); break; 
		case 3: 
			task2_state++; printf("task2: step 3\n"); break; 
		default: 
			printf("task2:  undefined step\n"); break; 
	}
}
int main(void)
{
	while(1)
	{
		if(count%1000==0)
			task1(); 
		if(count%2000==0)
			task2(); 
		rtc_interrupt(); 
	}
	return 0; 
}
```

任务的优先级如何处理?

# 操作系统基本原理

上面的程序通过计数器和状态机可以改变每个任务的执行频率和执行时间, 但还有一个问题没有解决: 无法修改每个程序的执行顺序. 每个任务都有轻重缓急之分, 每个任务的重要程度和该任务在系统中扮演的角色往往决定了这个任务的优先级, 优先级高的任务优先执行, 优先级低的任务排在后面执行. 我们接着对上面的程序进行改进. 

```c
#include<stdio.h>
#include<unistd.h>
#include<signal.h>

int task_delay[4]={0}; 
void task1(void)
{
	task_delay[0] = 10; 
	printf("task1...\n"); 
}
void task2(void)
{
	task_delay[1] = 4; 
	printf("task2...\n"); 
}
void task3(void)
{
	task_delay[2] = 4; 
	printf("task3...\n"); 
}
void task4(void)
{
	task_delay[3] = 1; 
	printf("task4...\n"); 
}
void timer_interrupt(void)
{
	for(int i=0; i<4; i++)
	{
		if(task_delay[i])
			task_delay[i]--; 
	}
	alarm(1); 
}

void (*task[])(void)={task1, task2, task3, task4}; 

int main(void)
{
	signal(SIGALRM, timer_interrupt); 
	alarm(1); 
	int i; 
	while(1)
	{
		for(i=0; i<4; i++)
		{
			if(task_delay[i]==0)
			{
				task[i](); 
				break; 
			}
		}
	}
	return 0; 
}
```

为了实现任务的优先级, 我们定义了一个函数指针数组, 用来存放各个任务的函数指针, 高优先级的任务放在数组前面, 低优先级的任务放在数组后面. 

在main()函数中, 我们根据每个任务的延时是否到期, 来决定是否执行这个任务. 当两个优先级不同的任务同时到期时, 因为高优先级任务的函数指针放在数组的前面, 会先被遍历到, 所以会先执行. 通过这种巧妙的设计, 我们就可以让高优先级的任务优先执行了. 

在多任务切换实现中, 为了模拟中断的产生, 我们使用了Linux系统提供的signal()和alarm()函数, 每1秒钟产生一个中断, 然后在中断程序里对各个任务做延时减1的操作, 任务延时到期后开始执行任务. 

## 调度器工作原理

继续分析: 多任务的优先级问题
- 任务的轻重, 紧急划分
- 任务的先后执行顺序

上面程序模拟的任务切换过程, 其实模仿的就是操作系统任务切换的基本流程. 如果我们对上面的程序进行封装, 实际上其已经很接近操作系统的调度器雏形了. 

```c
#include<stdio.h>
#include<unistd.h>
#include<signal.h>

int task_delay[4]={0}; 
void task1(void)
{
	task_delay[0] = 10; 
	printf("task1...\n"); 
}
void task2(void)
{
	task_delay[1] = 5; 
	printf("task2...\n"); 
}
void task3(void)
{
	task_delay[2] = 2; 
	printf("task3...\n"); 
}
void task4(void)
{
	task_delay[3] = 1; 
	printf("task4...\n"); 
}
void timer_interrupt(void)
{
	for(int i=0; i<4; i++)
	{
		if(task_delay[i])
			task_delay[i]--; 
	}
	alarm(1); 
}
void (*task[])(void)={task1, task2, task3, task4}; 
void os_init(void)
{
	task_delay[0] = 10; 
	task_delay[1] = 4; 
	task_delay[2] = 4; 
	task_delay[3] = 1; 
	signal(SIGALRM, timer_interrupt); 
	alarm(1); 
}
void os_scedule(void)
{
	int i; 
	while(1)
	{
		for(i=0; i<4; i++)
		{
			if(task_delay[i]==0)
			{
				task[i](); 
				break; 
			}
		}
	}
}
int main(void)
{
	os_init(); 
	os_scedule(); 
	return 0; 
}
```

我们将任务切换的核心代码封装成了os_init()和os_scedule()两个API函数, 然后在main()函数中, 可以直接调用这两个函数进行任务初始化和切换. 

调度器是操作系统中最核心的组件, 其主要功能就是负责任务的切换. 

在一个操作系统环境下, 一般是多个任务轮流占用CPU实现并发运行, 每个任务都是无限循环的, 如果调度器不去调度它们, 这个任务会一直霸占着CPU, 无限期地运行下去. 

调度器一般会按照时间片轮转法去切换任务: 每个任务运行10ms, 然后会有一个时钟中断或软中断产生, 打断当前正在执行的任务, 调度器会夺取CPU的控制权, 接着开始进行任务调度, 切换其他任务占用CPU继续运行, 如图. 
- 任务优先级
	- ![](assets/Pasted%20image%2020230512003406.png)
	- ![](assets/Pasted%20image%2020230512004056.png)

什么是调度器
- 调度器是操作系统的核心: 任务切换
- 多任务机制: 多个任务轮流使用CPU, 达到“并发”目的
- 任务: 每个任务是无限循环的
- 时间片轮转: 每个任务运行xx毫秒, 由时钟或软中断完成
	- ![](assets/Pasted%20image%2020230512003440.png)

调度器一般可分为可抢占型和不可抢占型. 
- 不可抢占型调度器按照时间片轮转给每个任务分配运行时间, 时间到了会有一个中断产生, 调度器重新夺取CPU的控制权, 然后安排下一个任务执行. 
- 可抢占型内核指一个任务的时间片还未到, 就可以被高优先级的任务打断, 抢占CPU, 然后开始运行高优先级的任务. 

实时操作系统对时间要求比较严格, 一般都是采用可抢占型内核, 而非实时操作系统对时间的要求不是很高, 一般采用不可抢占型内核. 

思考
- 操作系统中, 每个任务一般都是无限循环的
- 操作系统是如何做到任务切换的?
	- 时钟中断把控制权交还给内核去运行任务调度器
- 切换的时候要注意什么?
	- 保存现场

## 函数栈与进程栈

栈是C语言运行的基础. 在C语言函数运行期间, 接收的函数实参, 函数内定义的局部变量, 函数的返回值都是保存在栈中的. 

每一个函数都有一个对应的栈帧, 用来保存该函数内定义的局部变量, 函数实参, 函数的返回值, 上一级函数的返回地址, 上一级函数的栈帧地址等. 

在ARM平台下, 各个函数栈帧通过FP指针构成函数调用链. 
- 函数栈帧的作用
	- 保存函数上下文
	- 局部变量
	- 函数参数
		- ![](assets/Pasted%20image%2020230512004745.png)

在多任务环境中, 每个任务在运行过程中都有可能随时被打断, 随地被打断. 每个任务也都需要一个任务栈, 任务栈的作用主要有两个. 
- 任务执行期间, 函数调用需要的函数栈帧. 
- 保存被打断的任务现场: CPU的各种寄存器, 状态寄存器, 被打断地址等. 

任务栈

为什么需要任务栈?
- 任务被打断, 调度是随机的
- 作用1: 函数栈帧
- 作用2: 任务现场需要保存(状态寄存器, 被打断地址)

在uC/OS多任务环境下, 对于用户创建的每一个任务都需要显式指定一个任务栈. 如下面的示例代码所示. 
- 每个任务有独立的任务栈
	- ![](assets/Pasted%20image%2020230512004905.png)
		- 我们定义了一个task_stack数组来表示任务栈, 当用户使用uC/OS的API函数OSTaskCreate()去创建一个任务时, 需要显式指定该任务的栈空间起始地址&task_stack[1023]. 
		- 在ARM平台下, 因为我们使用的是递减栈, 所以要将数组的最高地址作为栈的起始地址, 当有栈元素入栈时, 栈从高地址向低地址方向不断增长. 
		- 当该任务运行时, 各个函数调用过程中需要的栈帧空间都保存在这个数组里; 
		- 当该任务被打断时, CPU寄存器, 被打断的地址等任务现场(上下文环境)也会保存在这个数组里. 

在Linux环境下, 对于每一个运行的程序, Linux操作系统都会将我们运行的程序包装成一个进程, 然后内核调度器通过统一的接口进行管理和调度. 

每一个运行的进程都有对应的进程栈, 这个栈一般位于用户空间的最高地址, 如图所示. 在ARM环境中使用的满递减栈, 栈空间从高地址向低地址方向不断增长. 
- ![](assets/Pasted%20image%2020230512005210.png)

进程栈的大小

- 设置合理的栈空间
	- 太大, 利用率低; 太小, 易产生栈溢出, 不安全
	- 函数调用, 函数调用层数
	- 局部变量, 数组大小
	- 中断函数, 中断调用层数

在Linux环境下编写一个应用程序, 为什么不显示指定栈?
- 加载运行一个应用程序就是一个进程
- 内核自动处理了栈的分配问题

## 可重入函数

在多任务环境下编程与在裸机环境下编程有很多不一样的地方, 函数的可重入性就是其中一个需要注意的细节. 什么是函数的可重入性, 我们先从一个实例开始介绍. 

```c
int a[10]={1, 2, 3, 4, 5, 6, 7, 8, 9, 0}; 
int b[20]={1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 12, 3, 4, 5, 6, 7, 8, 9}; 

int sum(int array[],  int len)
{
	static int sum = 0; 
	for(int i=0; i<len; i++)
		sum += i; 
	return sum; 
}
void task1(void)
{
	sum(a, 10); 
}
void task2(void)
{
	sum(b, 20); 
}
int main(void)
{
	return 0; 
}
```

多任务带来的问题
- 函数调用
	- 函数sum()被任务task1调用
	- 在调用过程中, 任务task1挂起
	- 调度器运行task2
	- 函数sum()被任务task2再次调用

由于sum()函数内定义的有静态变量, 当在运行期间被打断后再次被调用, 就有可能影响sum()函数在task1和task2中的运行结果. 

可重入函数

在一个多任务环境中, 一个函数如果可以被多次重复调用, 或者被多个任务并发调用, 函数在运行过程中可以随时随地被打断, 并不影响该函数的运行结果, 我们称这样的函数为可重入函数. 

相反, 如果一个函数不能多次并发调用, 在执行过程中不能被中断, 否则就会影响函数的运行结果, 那么这个函数就是不可重入函数. 

如何判断一个函数是可重入函数, 还是不可重入函数呢?规则很简单, 一个函数如果满足下列条件中的任何一个, 那么这个函数就是不可重入函数. 

- 函数的可重入
	- 可重复调用, 并发调用, 可以被中断
	- 在多任务环境中, 多次调用, 不影响运行结果
	- 一般应用在多任务, 多进程的运行环境中
- 不可重入函数
	- 满足条件
		- 函数内部使用了全局变量, 静态局部变量
		- 函数返回全局变量或静态局部变量
		- 函数内部使用了malloc/free函数
		- 函数内部使用了标准I/O函数
		- 函数内部调用了其它不可重入函数

如下面的两个swap() 函数, 如果在设计过程中, 使用了全局变量或静态变量, 那么这个函数就变得不可重入了, 在多任务环境中并发运行可能会出现问题. 
```c
int tmp; 
void swap(int *p1,  int *p2)
{
	tmp = *p1; 
	*p1 = *p2; 
	*p2 = tmp; 
}
void swap(int *p1,  int *p2)
{
	static int tmp; 
	tmp = *p1; 
	*p1 = *p2; 
	*p2 = tmp; 
}
```

在裸机环境下面, 我们不需要考虑函数的可重入问题, 因为裸机环境下只有一个主程序main()一直在独占CPU运行. 

但是在多任务环境下, 如果该函数可能被多次调用, 或者在执行过程中可能会被中断或被任务调度器打断, 此时我们就要考虑该函数的可重入问题了. 

如何让一个函数变得可重入呢?方法其实也很简单, 在函数设计的时候遵循下面的设计原则即可. 
- 应用场合
	- 多任务环境, 该函数可能被多次调用
	- 该函数在执行过程中可能会被中断, 任务调度打断
- 设计原则
	- 函数内部不使用静态变量, 全局变量
	- 函数返回值不能是全局变量或静态变量
	- 不使用标准I/O函数
	- 不使用malloc/free函数
	- 不调用不可重入函数

上面设计原则的前4条都比较容易实现, 比较难把握的是第5条. 我们在编程过程中可能会调用各种各样的函数: C标准库函数, 第三方库函数, 框架接口函数, 操作系统的API函数, 以及自定义函数等. 很多时候我们调用的函数只能通过头文件看到其函数原型声明, 并无法真正看到其内部实现, 所以在调用这些函数的过程中要特别注意, 要看这些函数是否是可重入的. 

安全编程指南
- 在中断函数中尽量不调用不可重入函数
	- C标准库函数
	- 第三方库, 框架接口函数
	- 操作系统的API函数
	- 自定义函数

在中断函数中一般尽量不要调用不可重入函数, 为什么?
- 不可重入函数如果被别的线程或进程多次调用那么中断函数也调用了这个函数就会导致结果出现不正确的情况而影响程序执行
如果真的调用了, 就一定会出现问题吗?为什么?
- 未必
- 如果别的地方没有调用过这个函数就能用

## 临界区与临界资源

在实际编程中, 我们会不可避免地在函数中使用全局变量或静态局部变量, 或者调用malloc()/free()函数, 或者调用printf()/scanf()等标准I/O函数, 那么这个函数也就变得不可重入了. 不可重入函数在多任务环境下运行, 有可能随时被中断, 被任务切换打断, 进而会影响运行结果. 这可怎么办呢?

操作系统在实现多任务调度时, 早就想到这一点了: 一个函数之所以变得不可重入, 主要因为在函数内部使用了全局变量, 静态变量这些公共资源. 

如果我们在访问这些全局资源时采取一些安全措施, 对这些资源实行互斥访问, 或者在访问这些资源的时候不允许被打断, 那么这个不可重入函数不也变得安全了吗?

操作系统就是这么干的. 操作系统可以通过信号量, 互斥量, 锁等机制对这些资源进行互斥访问, 一次只允许一个任务访问这些资源, 同一时刻也只允许一个任务访问这些资源, 如全局变量, 静态变量, 缓冲区, 打印机等, 这些资源也被称为临界资源. 

与临界资源对应的就是临界区, 所谓临界区其实就是访问临界资源的代码段. 临界区的访问方式是互斥访问, 同一时刻只允许一个任务访问. 不同的操作系统一般都会有专门的操作原语来实现临界区. 
- EnterCriticalSection()
- LeaveCriticalSection()

临界区实现方式可以有多种: 
- 可以直接关中断
- 也可以通过互斥访问实现, 如信号量, 互斥量, 自旋锁等

如在uC/OS中, 临界区一般通过关中断的方式实现. 
- ![](assets/Pasted%20image%2020230512011725.png)

uC/OS 临界区实现

在不同平台下, 临界区实现的方式可能不一样, 或者通过不同的指令去关中断和开中断. 
```c
#if OS_CRITICAL_METHOD == 1
#define OS_ENTER_CRITICAL() __asm__("cli") /* Disable interrupts */
#define OS_EXIT_CRITICAL() __asm__("sti") /* Enable interrupts */
#endif

#if OS_CRITICAL_METHOD == 2
#define OS_ENTER_CRITICAL() __asm__("pushf cli") /* Disable interrupts */
#define OS_EXIT_CRITICAL() __asm__("popf") /* Enable interrupts */
#endif

#if OS_CRITICAL_METHOD == 3
#define OS_ENTER_CRITICAL() (cpu_sr = OSCPUSaveSR()) /*Disable interrupts*/
#define OS_EXIT_CRITICAL() (OSCPURestoreSR(cpu_sr)) /*Enable interrupts*/
#endif
```

在Linux或Windows环境下, 临界区一般可以通过加锁, 解锁的方式来实现. 
- 加锁: pthread_mutex_lock
- 解锁: pthread_mutex_unlock
	- ![](assets/Pasted%20image%2020230512011944.png)

# 系统调用

什么是系统调用?想了解系统调用的来龙去脉, 我们可以从代码复用的角度, 并以此作为切入点进行学习. 

代码复用
- 函数调用
	- 自定义函数
	- C标准库
	- 第三方库
	- 框架
	- 操作系统

## 操作系统的API

在一个ARM开发板上, 如果我们想使用uC/OS去创建一个多任务并发运行的环境, 直接调用uC/OS实现的API函数, 就可以很方便地创建多个任务. 
- ![](assets/Pasted%20image%2020230512012609.png)

uC/OS其实并不是一个操作系统, 它只能算是一个操作系统内核, 或者称作调度器. 

现代操作系统随着集成的组件越来越多, 功能也越来越完善, 系统也越来越复杂, 支持各种各样的功能, 如网络通信, 进程管理, 文件系统, 内存管理, 协议栈, 设备管理, GUI等. 

随着系统越来越复杂, 带来的各种问题也越来越多, 如硬件安全访问, 资源访问冲突, 系统稳定运行等越来越受到挑战. 

现在很多嵌入式系统的底层驱动和上层应用开发都是分离的, 由不同的团队和个人开发. 假如有一个App开发者, 调用了操作系统的一些API, 对硬件进行了一些非法操作, 或者对内存进行了非法访问, 篡改了操作系统内核的一些核心代码, 可能就导致整个系统崩溃了. 

## 操作系统的权限管理

为了防止上面这种状况发生, 现代操作系统一般会实行权限管理, 如指令运行权限, 内存访问权限, 硬件资源访问权限等, 不同的代码有不同的权限. 

在Linux环境下, 应用程序不能像调用uC/OS的API函数一样, 直接去调用Linux操作系统内核实现的各种API. 

Linux操作系统运行时一般分为内核态和用户态, 应用程序运行在用户态, 操作系统内核和驱动运行在内核态, 操作系统在内核态可以访问系统任意资源, 而用户程序在用户态时访问这些资源则会受到限制. 

那么如果应用程序想访问一些受限制的硬件资源该怎么办, Linux操作系统会留出一些专门的API供用户使用. 当用户想访问一些权限受限的资源时, 可以通过调用这些系统调用API来完成. 通过系统调用, Linux会从用户态转换到内核态, 然后就有权限访问任意资源了. 
- ![](assets/Pasted%20image%2020230512014117.png)

权限管理
- 函数调用权限
- 内存访问权限
- 资源访问权限

Linux设计哲学
- 对不同的操作赋予不同的执行等级
- 内核态可访问任意系统资源, 用户态程序访问权受限

用户态与内核态
- 操作系统特权
	- 用户态
	- 内核态
		- 系统调用: int 0x80;  swi
		- 内部异常
		- 外部中断

## CPU的特权模式

Linux的操作系统特权是如何实现的呢?为什么这些资源在用户态下不可访问, 而在内核态下就可以访问了呢?

这主要与CPU的特权等级有关, 不同的CPU有不同的运行等级, 如X86处理器就有4个运行等级, 分别为ring0, ring1, ring2, ring3. ring3等级最低, 一般应用程序会运行在这个等级, 对应操作系统的用户态. 

在用户态下应用程序访问I/O等系统硬件资源就会受到限制, 无法运行一些特权指令. 

ring0是特权等级, 操作系统内核代码一般运行在这个等级, 对应操作系统的内核态, 在这个运行等级下, CPU可以运行各种特权指令, 访问I/O等系统硬件资源, 完成内存读写, 寄存器配置等各种特权操作. 

ARM处理器也有不同的运行等级, 一般分为用户模式和特权模式. 
- 当ARM处理器工作在USR模式时属于用户模式, 
- 当ARM处理器工作在SYS, FIQ, IRQ, SVC, ABT, UND模式时属于特权模式. 

ARM在特权模式下可以运行一些特权指令, 如MSR, MRS指令. 

当ARM处理器工作在普通模式时, 对应的操作系统就运行在用户态, 访问一些硬件资源或运行特权指令就会受到限制. 

当ARM处理器工作在特权模式时, 对应的操作系统就运行在内核态, 此时一些受限资源的访问, 特权指令都可以运行. 

应用程序一般运行在用户态, CPU工作在普通模式, 此处CPU执行的是普通指令. 当发生外部中断, 内部异常或系统调用时, CPU就会进入特权模式, 此时操作系统也进入内核态, CPU开始执行特权级内核代码. 

以系统调用open为例, CPU从系统调用到执行内核代码, 到返回用户态继续执行应用程序的代码, 整个基本流程如下. 
- 应用程序解析参数, 调用系统调用API: open. 
- Linux通过软中断进入内核态, CPU进入特权模式, 控制权交给OS, 参数放在寄存器中. 
- CPU从系统调用表中查询open系统调用对应的代码内存地址. 
- 从寄存器获取参数, 执行open对应的操作系统内核代码. 
- 内核代码执行结束, 将运行结果复制到用户态. 
- CPU由特权模式切换到普通模式, 操作系统由内核态返回到用户态. 
- CPU执行用户态代码, 继续在用户态运行. 

CPU的特权等级小结: 
- X86处理器
	- ring0: 内核代码: 15条特权指令 + I/O + 内存访问特权
	- ring1/ring2
	- ring3: 应用程序: I/O等系统资源访问受限
- ARM处理器
	- 特权模式: SYS, FIQ/IRQ, SVC, ABT, UND + 特权指令MSR, MRS等
	- 用户模式: USR

系统调用

基本概念
- 操作系统提供给应用程序调用的接口
- 用户态: 应用程序运行状态, CPU执行特权级为3的用户代码
- 内核态: 通过系统调用, CPU执行特权级为0的内核代码
	- ![](assets/Pasted%20image%2020230512014117.png)

系统调用的优点
- 简化应用程序开发
	- 为应用程序提供一个统一的硬件抽象接口
	- 分离了用户程序和内核驱动的开发
- 权限管控, 保证了系统的稳定和安全

## Linux系统调用接口

Linux系统为用户提供了大量的系统调用接口. 通过这些系统调用接口, 用户程序可以更加安全地访问系统的相关硬件资源, 读写磁盘数据, 通过网卡通信, 读写内存空间, 如表所示. 
- ![](assets/Pasted%20image%2020230512014432.png)

Linux系统有不同的发行版本, 如RedHat系, Debian系等, 每个版本甚至还有不同的分支. 随着版本不断更新迭代, 各个版本的差别也越来越大, 包括这些系统调用接口, 不同的操作系统可能实现的接口不一样, 这就导致我们在一个Linux版本下开发的程序到了另一个Linux环境下可能就无法运行. 

为了避免这一状况, POSIX标准出现了, POSIX标准即Portable Operating System Interface for Computing Systems, 它为不同版本的Linux和UNIX操作系统统一了应用程序系统调用接口, 无论是哪个版本的Linux系统, 在实现系统调用接口时都要遵循这个标准, 这就是为什么你写的程序在Linux平台或UNIX平台都可以运行. 

/usr/include/unistd.h头文件下去查看这些标准的系统调用接口. 

## 系统调用与C标准库

区别与联系
- 系统调用运行于内核态, C库函数运行于用户态
- C标准库函数实现: 对系统调用的二次封装
	- ![](assets/Pasted%20image%2020230512014759.png)

库函数与系统调用调用流程对比

```c
#include <stdio.h>

int main(void) {
  FILE *fp; 
  fp = fopen("1.dat",  "ab+");  //库函数
  if (fp == NULL) {
    printf("open file failed!\n"); 
    return -1; 
  }
  fwrite("111",  1,  3,  fp);  //标准库写入
  fclose(fp); 
  return 0; 
}
```

系统调用
```c
#include <fcntl.h>
#include <stdio.h>
#include <unistd.h>

int main(void) {
  int fd; 
  fd = open("2.dat",  O_RDWR | O_CREAT,  0600);  //系统调用
  printf("fd: %d\n",  fd); 
  write(fd,  "111",  3);  //系统调用
  close(fd); 
  return 0; 
}
```

分别用strace去跟踪system call的流程.

# 中断

在上面的多任务裸机实现中, 我们通过中断来进行任务切换, 在实际的操作系统源码中, 内核调度器其实也是通过中断来完成进程调度和任务切换的. 

中断的用途不仅仅用在任务切换中, 操作系统中的系统调用, 内存管理等各种机制其实都是基于中断实现的. 中断是我们学习和理解操作系统的一个很好的切入点, 理解不了中断, 也就掌握不了操作系统的精髓. 

## 中断处理流程

在一个计算机系统中, CPU同外部设备的通信一般分为两种方式: 同步通信和异步通信, 对应的实现方式分别是轮询和中断. 

这和老张烧水是同一个道理: 在烧水的过程中, 如果老张什么都不做, 每隔一分钟都要跑过来看看水烧开了没有, 这就是轮询; 如果在烧水的过程中, 老张跑去看电视了, 等水烧开后, 鸣笛通知老张, 这就是中断. 

中断的好处就是不占用CPU的资源, 在烧水期间, 老张可以干其他事情, 不用坐在那里干等. 

中断的概念
- 轮询与中断
	- 老张烧水的故事
	- 同步通信: 占用CPU资源
	- 异步通信: 节省CPU资源
		- ![](assets/Pasted%20image%2020230512015550.png)

CPU和外部设备的通信也是一样, 像串口, 鼠标, 键盘这种慢速设备, 和CPU的运行速度相比, 有成千上万倍的差距, 根本不在一个数量级上. 

如果采用轮询式的同步通信, 浪费CPU资源. 而采用中断这种异步通信方式就不会存在这种问题, 外部设备在数据的发送和接收过程中, CPU该干啥干啥, 两者互不冲突, 等外部设备数据接收或发送完毕, 以中断的形式通知CPU, CPU再过来处理就可以了. 

通过中断的通信方式, 既没有浪费太多的CPU资源, 又完成了数据的通信. 

中断的重要性
- 时钟是操作系统的“心脏”
- 中断是理解操作系统的切入点
	- 系统调用
	- 任务调度
	- 内存管理

在一个嵌入式系统中, 和CPU进行通信的有很多外部设备, 如串口, U盘, 键盘, 鼠标, 网卡, I2C设备等. 当外部的一个中断到来时, CPU怎么知道是哪个设备发生的中断呢?这里就涉及中断号或中断线的概念了, 如图所示. 
- 中断号与中断线
	- ![](assets/Pasted%20image%2020230512015844.png)

在一个ARM SoC芯片中, 芯片上集成了不同的外部设备或`外部设备控制器`, 对于每一个外部设备都有一个`固定的中断号`. 

SoC芯片内部通常会集成一个专门管理中断的模块: 中断控制器. 

中断控制器通常通过一根或两根中断信号线与CPU相连. 

- 当外部设备发生中断时, 会首先将中断信号传送到中断控制器, 
- 中断控制器通过中断屏蔽, 优先级, 中断是否使能等各种条件判断和检测, 然后将中断信号发送到CPU, 
- CPU检测到中断之后, 就会搁置当前正在执行的任务, 查看相关寄存器, 看是哪个设备发生了中断, 再跳转到对应的中断处理程序执行中断操作. 

- 这里我们所讨论的中断, 一般指外部中断. 
- 除此之外, 处理器还有异常的概念. 
	- CPU在执行程序的过程中遇到未定义指令, 或者运行出错了一般也会发生中断, 只不过这种中断源不是来自外部设备, 而是来自CPU内部. 

广义的中断
- 任何打断系统正常执行的流程都可以叫作中断
- 一般称CPU内部中断为内部异常
- 外部中断
- 软中断

ARM处理器有多种中断模式, 如Reset, Undefined Instruction, Software Interrupt, Prefetch Abort, Data Abort, IRQ, FIQ, 如图所示. 

中断向量表
- 中断跳转机制
	- ![](assets/Pasted%20image%2020230512020444.png)

当中断发生时, ARM处理器中的PC指针会跳到中断向量表去执行, 根据发生中断的类型, 跳转到向量表中不同的入口地址上. 

对于每一种中断模式, 在向量表中只有一个字的存储空间, 因此在向量表中存储的往往是一条跳转指令, 当发生中断时, 跳转到不同的中断处理函数中去执行. 

每个中断的中断处理例程(Interrupt Service Routines, ISR)都有对应的中断处理函数. 在中断处理函数中需要做什么操作, 需要工程师根据自己的业务需要或功能需求自己编写. 当中断发生时, ARM处理器在硬件上也会自动完成一部分事情, 这些就不需要软件操作实现了. 

IRQ中断处理流程
- ![](assets/Pasted%20image%2020230512020640.png)
	- 在ARM处理器中, 当有IRQ中断发生时, CPU会自动保存CPSR寄存器到发生中断模式下的SPSR_irq, 设置CPSR位. 
	- 将当前处理器模式设置为ARM状态, IRQ模式, 并关闭中断, 然后将被打断的应用程序地址0x6000000C保存到LR_irq寄存器中, 将PC指针设置为0x00000018, 程序就跳转到中断向量表去执行了. 
	- 在中断向量表的0x00000018地址处是一个跳转指令, 会跳到IRQ的中断处理函数IRQ_handler()执行. 
	- 在IRQ_handler()函数中, 首先要保护被打断的当前程序的现场: 将各种寄存器, CPU状态压入栈中保存, 然后根据中断号跳转到具体外部设备的中断处理函数中去执行. 
	- 中断处理完毕后, 再恢复原来被打断的应用程序现场, 将栈中保存的CPU状态, 各种寄存器值重新弹出到CPU的各个寄存器中, 重新运行被打断的程序. 

这里有一个细节需要注意: 当函数调用返回时, 一般返回的是当前调用指令的下一条指令; 而中断返回时, 一般返回到当前指令处继续执行(如图, 返回到0x60000008地址执行, 而不是返回到0x6000000C)而我们的链接寄存器中自动保存的是被打断指令的下一条指令地址0x6000000C. 因此, `在中断处理函数中记得要将LR寄存器中的返回地址减4`. 

## 进程栈与中断栈

在一个多任务环境中, 每个任务都要有自己的任务栈, 一是为了给函数调用过程中的每个函数准备栈帧空间, 二是当该任务被打断时, 需要将该任务的现场环境(上下文环境)保存到当前的任务栈中. 

栈的用途
- 栈是C语言运行的基础
	- 函数调用: 局部变量, 函数参数, 返回地址, 寄存器
	- 现场保护: 状态寄存器 , 寄存器, 返回地址

什么是任务的上下文环境呢?当一个任务被打断后, 我们需要保存的任务现场, 到底要保存什么东西呢?

- 在一个多任务环境中, CPU如果想运行一个任务, 直接将CPU内部的PC指针指向这个任务的函数体就可以了, PC指向哪里, CPU就到哪里取指令运行. 
- 程序运行时, 还需要将CPU内部的寄存器SP指向一个栈空间, 因为函数内的局部变量, 传递的实参, 返回值都是保存在栈内的, 没有栈, C语言就无法运行. 
- CPU对栈内数据的访问是通过FP/SP+相对偏移实现的. 因为是相对寻址, 所以`栈是与位置无关的`, 把栈放到内存中的任何地方都不会影响程序的运行. 
- 只要提供一片内存空间, SP指针指向哪里, CPU就可以在哪里建立函数运行的栈帧环境; 
- PC指针指向哪里, CPU就到哪里去取指令, 运行一个个C语言函数, 如图所示. 
	- ![](assets/Pasted%20image%2020230512021649.png)

每次函数调用, 系统都会在内存中为函数分配一个栈帧空间, 每次分配的栈地址都是不一样的, 但并不影响程序的运行: 只要提供一片内存, 无论在什么地方, 函数都能正常运行. 

虽然栈的位置与地址无关, SP指向哪里程序都能运行, 但是SP指针一般也不会乱指. 每个任务都有自己的任务栈, 当CPU运行不同的任务时, 我们让SP栈指针分别指向每个任务各自的任务栈, 如图所示. 
- 进程上下文
	- ![](assets/Pasted%20image%2020230512021417.png)

ARM处理器属于RISC架构, 不能直接处理内存中的数据, 要先通过LDR指令将内存中的数据加载到寄存器, 处理完毕后再通过STR指令回写到内存中, 每一次数据的处理都需要加载/存储操作来辅助完成. 

如果在CPU处理数据的过程中任务被打断, 保存现场时这些寄存器的值也要保存起来, 再加上ARM处理器中的状态寄存器CPSR等, 它们和PC, SP寄存器一起构成了程序运行的现场, 即任务上下文环境. 

在操作系统的源码实现中, 调度器为了更好地管理每一个任务, 一般会为每个任务定义一个结构体. 如下图所示, 每个结构体内都有指向当前任务函数体和进程栈的指针. 各个任务的结构体通过指针链接成一个双向循环链表, 调度器通过这个链表来管理和调度每一个任务. 
- ![](assets/Pasted%20image%2020230512022048.png)
	- 当一个正在运行的任务被打断, CPU切换到另一个任务执行之前, 首先要做的就是保存当前任务的现场, 即任务上下文, 包括PC指针, SP指针, 各种寄存器等. 
	- 这些现场一般会保存到各个任务的任务栈中(SP指针一般会保存在各个任务的结构体中, 为了简化分析, 这里假设所有上下文都保存到了栈中). 
	- 以task3为例, 当task3不再运行时, 它的任务上下文会首先保存到自己的任务栈中, 然后将task2的上下文环境恢复到CPU的PC, SP等寄存器中. 
	- 此时, PC指针指向task2的代码段, SP指针指向task2的任务栈空间, CPU开始执行task2. 
	- 如果task2执行一段时间后再被切换出去执行task3, 操作系统会首先保存task2的任务上下文到它的任务栈中, 然后把task3的任务上下文弹出到CPU中就可以了, task3就像没有被打断过一样, 从原来被打断的地方继续运行. 

Linux系统使用了内存管理, 一个进程空间被划分为内核空间和用户空间. Linux普通进程运行在用户空间, 进程运行需要的栈也是在用户空间, 这种栈一般被称为进程栈, 或用户进程栈. 

用户空间的程序是无法访问内核空间的, 那么问题就来了: 当用户程序调用系统调用函数时, 操作系统就会由用户态转为内核态, CPU开始执行内核里的代码, 内核代码在运行过程中, 各种函数调用也是需要栈空间的, 这个栈从哪里分配呢?

Linux操作系统一般会在内核空间`给每个进程`都分配4KB或8KB大小的栈空间, 我们一般称这种栈为内核栈. 
- ![](assets/Pasted%20image%2020230512022525.png)
- 当一个进程在用户态和内核态交互运行时, 就会用到这两种进程栈, 这时候就涉及SP指针的切换了. 一个进程的用户栈和内核栈会通过结构体的一些指针建立关联, SP栈指针可以通过这些关联信息进行切换, 随着进程执行环境的变化分别指向不同地址空间的栈. 

除了用户栈和内核栈, 一个程序在内存中运行时, 还经常用到的一种栈叫中断栈. 

当中断发生时, CPU会通过中断向量表跳转到对应的中断处理函数中运行. 中断处理函数也是函数, 运行中断处理函数也需要栈的支持. 中断处理函数中的各级函数调用, 被中断打断时的现场保护也需要栈空间, 这个栈因此也被称为中断栈. 

中断栈分为两种: 独立中断栈和共享中断栈. 

- 独立中断栈有自己独立的栈空间, 而共享中断栈则和任务栈共享内存空间. 一个任务在执行期间被中断打断后, SP指针会指向中断栈, PC指针会指向中断处理函数, CPU然后就跳转到中断处理函数中去执行了. 
- 如果此时再来一个中断, 发生了中断嵌套, 操作系统会把当前的中断上下文保存到中断栈中, 然后跳转到新的中断函数中去执行, 如图所示. 
	- ![](assets/Pasted%20image%2020230512022816.png)

在Linux环境下, 当发生中断时, 操作系统一般都会进入内核态, 所以中断栈会和Linux内核栈共享内存空间. 

操作系统为`每个进程的内核栈`分配的内存空间并不大, 一般为4KB或8KB, 与用户态8MB大小的栈空间相比, 资源比较紧张. 这就决定了我们在编写中断函数时要注意栈空间的使用情况, 中断函数内一般不要使用大块的内存, 中断函数的调用层数, 中断嵌套也不要太深, 防止因中断栈溢出而导致系统崩溃. 

Linux中断栈
- 中断栈
	- 跟内核栈共享内存空间
	- 独立中断栈: 硬中断栈, 软中断栈
- 栈空间大小
	- 任务函数体局部变量, 参数
	- 函数调用层次
	- 中断嵌套层次

## 中断函数的实现

对于处理器发生的每一个外部中断, 程序员都要编写对应的中断处理函数来执行相关的操作, 如接收数据, 发送数据, 处理数据等. 

在裸机环境和有操作系统的环境下编写中断函数和普通函数不太一样, 我们在编写中断函数前, 首先要了解一下中断函数的一些特性和基本处理流程. 

在一个多任务环境中, 中断可以随时随地打断当前正在执行的任务, 并且中断执行结束后, CPU还不一定返回原先被打断的任务执行. 

中断特性
- 可随时打断正在执行的任务
- 可在任何地方打断正在执行的任务
- 中断返回后, CPU不一定重新执行被打断的任务

中断的这个特性导致我们在编写中断函数时要注意以下3点. 
- 中断函数被调用时间不固定: 中断函数要自己保护现场
- 中断函数被调用地点不固定: 当前的任务无法给中断函数传参
- 中断函数的返回地点不固定: 中断函数不能有返回值

裸机环境下的中断函数

在一个嵌入式ARM裸机环境下, 如果我们编写一个中断处理函数, 一般要遵循以下基本流程. 
- 保存中断现场
	- 状态寄存器, 返回地址入栈
	- 中断函数ISR中要使用到的寄存器入栈
- 清中断: 关中断, 保护现场, 有些硬件自动清除, 重启开启中断前记得要清除
- 执行用户编写的中断处理函数
- 恢复现场
	- 将栈中保存的数据弹到CPU的各个寄存器中, 恢复被中断的现场
	- 从栈中弹出返回地址到PC寄存器, CPU从被打断的程序继续执行

在一个中断函数中, 任务的现场保护和现场恢复一般需要用汇编语言来实现, 各种入栈出栈的汇编指令操作编写起来比较麻烦. 

为了编程方便, 各种ARM编译器或IDE一般会提供一些关键字, 如ARM编译器提供的`__irq`关键字, C51编译器提供的`interrupt`关键字, 当我们在中断函数前使用这些关键字修饰时, 编译器在编译这个函数时, 会自动帮我们实现现场保护和恢复的汇编代码, 就不需要程序员手动编写了. 

程序员只需要关注自己的业务逻辑实现就可以了, 底层的现场保存和恢复交给编译器来完成, 从而大大减轻了工作量. 

中断函数的编写因为这些关键字的辅助也就变得非常简单, 但我们还是不能掉以轻心, 在编写中断函数时, 还是需要遵守一些基本原则的. 
- 中断函数不能有返回值
- 不能向中断函数传递参数
- 不能调用不可重入函数, 如printf(). 
- 不能调用引起睡眠的函数. 
- 中断函数应短小精悍, 快速执行, 快速返回. 

在一个多任务环境中, 中断处理函数还涉及任务调度的问题. 当中断处理完毕要退出时, 不一定会返回到原先被打断的任务继续执行, 它会找出当前优先级最高的就绪任务, 然后开始执行它. 

以uC/OS内核为例, 它的中断函数处理流程如下. 
- 保存被打断的task1任务现场: 各种寄存器, 返回地址PC, 任务栈指针SP. 
	- 状态寄存器, 返回地址PC压入task1任务栈
	- 中断函数中要用到的通用寄存器压入task1任务栈
	- 保存当前的任务栈指针SP //这一步往往需要手动
- 中断嵌套计数加1: 中断嵌套计数主要用来判断当前是否还在中断上下文中, 是否需要任务调度. 
- 执行用户编写的中断处理函数. 
- 任务调度: 查找下一个要执行的高优先级就绪任务task2.   //调用OS的API
- 恢复现场: 将task2任务栈中的寄存器, 栈指针弹出, 通过中断返回指令, 从任务栈中弹出返回地址到PC, 然后开始执行task2. 

Linux操作系统的中断处理比较复杂, 在Linux内核中现在已经有专门的中断处理框架来管理和维护中断, 在Linux环境下编写中断处理函数也就变得不一样了, 如图所示. 
- Linux中断处理框架
	- ![](assets/Pasted%20image%2020230512030353.png)


在Linux环境下编写中断处理函数, 一般要通过中断处理子系统提供的API将中断处理函数注册到系统中. 当中断发生时, 再以回调的形式执行用户编写的中断处理函数. 和中断处理函数相关的API函数定义如下. 

Linux下的中断函数
- 中断函数实现
	- 返回类型: `typedef irqreturn_t (*irq_handler_t)(int,  void *); `
	- 函数形式: `irqreturn_t keyboard_isr(int irq,  void *dev_id); `
	- 中断注册: `request_irq(unsigned int irq,  irq_handler_t handler, unsigned long flags,  const char *name,  void *dev)`

在Linux环境下编写中断处理函数虽然比在裸机环境下灵活方便了很多, 但还是有一些规则需要遵守的. 
- 如在中断上下文中, 要禁止任何进程切换. 
- 在中断处理函数中不能调用可能会引起任务调度的函数, 如一些可能会引起CPU睡眠的函数, 引起阻塞的函数, 或者其他一些导致调度器介入执行, 发生任务切换的函数. 

# 存储器接口与映射

一个嵌入式系统通常会支持多种启动方式: 从NOR Flash启动, 从NAND Flash启动或者从SD卡启动. 一个嵌入式产品可以根据自己的业务需求和成本考虑, 选择灵活的存储方案和启动方式. CPU通过不同的存储接口和存储映射, 为各种灵活的启动方式提供底层技术支撑. 

## 存储器与接口

嵌入式存储器

不同类型的存储器
- 读写速度
- 读写方式
- 价格工艺
- 容量大小

常见的存储器
- ROM
- Flash
- SRAM
- DRAM

存储器分类
按存储模式
- ROM 只读存储器
	- Read Only Memory: 只读, 不能写, 数据断电不消失
	- PROM: 可编程ROM, 可以写一次, 可使用特殊设备写入数据. 
	- EPROM: 可多次紫外线照射擦除
	- EEPROM: 可多次电擦除, 可访问和修改任何一个字节
	- Flash : 广义的EEPROM, 以块为单位擦除

EEPROM一般容量较小, 价格也比较贵, 所以在嵌入式系统中应用得不是很广泛. 现在嵌入式系统比较常用的存储器是Flash, Flash具有容量大, 价格便宜等优势, Flash存储经过这么多年的发展, 技术也在不断地迭代升级. 
- FLASH
	- NOR Flash: 数据线, 地址线分开, 具有随机寻址功能
	- NAND Flash : 数据线, 地址线复用, 不能随机寻址, 按页读取
	- eMMC: 将NAND Flash和读写控制器封装在一起, 使用BGA封装. 对外引出MMC接口, 用户可以通过MMC协议读写NAND Flash, 简化了读写方式. 
	- SD: 将NAND Flash和读写控制器封装在一起, 使用SIP封装, 对外引出SDIO接口, 用户可以使用SDIO协议进行读写, 简化了NAND Flash的读写方式. 
	- 3D/2D Nand: SLC, MLC, TLC
		- SLC一个晶体管只能表示1bit数据, 分别用高, 低电平表示1和0; MLC则可以使用四个电平表示2bit内容; TLC则可以使用8个不同的电平表示3bit数据. 
	- SSD: 将NAND Flash存储器阵列和读写控制器封装在一起. 
- RAM 随机寻址存储器
	- Random Access Memory,  可读, 可写, 数据断电消失
	- SRAM: 静态随机存储器, 读写速度快, 成本高(1bit 6个晶体管)
		- 一般作为CPU内部的寄存器, Cache, 片内SRAM使用
	- DRAM: 动态随机存储器, 成本低(1bit=1个晶体管+1个电容), 需要刷新
		- DRAM读写速度相比SRAM会慢很多, 而且DRAM读写还需要控制器的支持. 
	- SDRAM: Synchronous DRAM: 省去电容充电时间, 流水线操作
		- 将DRAM的读写速度提高了不少, 再加上其存储成本低, 容量大等优势, 因此在嵌入式系统, 计算机中被广泛使用
	- MCP: eMCP, ND MCP
- SDRAM
	- 常用作内存: 容量大, 价格便宜, 访问速度快, 需控制器支持
	- DDR SDRAM: 2.5V, Dual Data Rate SDRAM, 时钟上升/下降沿
	- DDR2: 1.8V, 4Bit预取, 800Mbps
	- DDR3: 1.5V, 8Bit预取, 1600Mbps
	- DDR4: 1.2V, 3200Mbps
	- DDR5: 1.1V, 6400Mbps

存储器接口

不同的存储器使用不同的接口与CPU相连, 存储器接口按访问方式一般分为SRAM接口, DRAM接口和串行接口3种. 
- SRAM接口
	- 全地址/数据总线接口: 地址和存储单元一一对应, 支持随机寻址
	- CPU可以直接访问, 随机读写
	- SRAM和NOR Flash一般都采用这种接口与CPU相连
	- ![](assets/Pasted%20image%2020230512033139.png)
- DRAM接口
	- 采用行地址选择(RAS)+列地址选择(CAS)的地址形式, 地址线是复用的, 一个地址需要多个周期发送
	- CPU不能通过地址线直接访问DRAM, 要通过DRAM控制器按照规定的时序去访问DRAM的存储单元
	- DRAM, SDRAM一般都是采用DRAM接口与CPU处理器相连
	- ![](assets/Pasted%20image%2020230512033351.png)
- 串行接口
	- 串行通信的方式发送地址和数据, 速度慢
	- 优势是接口的管脚比较少, 占用CPU的管脚资源相对较少
	- E2PROM, NAND Flash, SPI NOR Flash一般都采用这种接口
		- ![](assets/Pasted%20image%2020230512033532.png)

在嵌入式开发中, 根据业务需求和成本考虑, 我们通常会设计出不同的存储方案. 
NANDFlash容量大, 存储成本低, 目前成为嵌入式存储的主流标配. 但是因为其不支持随机访问, 所以有时候我们会选择和一个NOR Flash搭配使用, 让系统从NOR Flash启动, 数据采用NAND Flash存储. NAND Flash还有一个缺点是读写的次数多了, 可能会产生很多坏块, 因此对于一些非常重要的系统或配置数据, 我们可以考虑把它们存储在E2PROM或SPI NOR FLASH中. 

对于一些移动设备, 如手机, 平板电脑, 蓝牙音箱, 投影仪等, 还可以通过SD卡这些可插拔的存储设备来扩充存储容量. 这些不同的存储选择也就决定了嵌入式系统不同的启动方式. 
- 嵌入式存储系统
	- ![](assets/Pasted%20image%2020230512033738.png)

## 存储映射

在一个嵌入式系统中, 不同的存储方案设计往往`决定了这个系统的启动方式`. 
ARM处理器上电复位后, PC寄存器为0, CPU默认是从零地址去读取指令执行的. 

我们可以通过存储映射, 将不同的存储器映射到零地址, 那么CPU复位后, 就可以到不同的存储器取指令运行, 从而实现多种启动方式. 

在学习存储映射之前, 我们先了解一下`地址和存储单元之间的关系`, 如图所示. 
- ![](assets/Pasted%20image%2020230512034013.png)
- ![](assets/Pasted%20image%2020230512034023.png)

以SRAM为例, CPU可以通过SRAM接口直接与SRAM相连, 对于CPU管脚上发出的一组地址信号, SRAM内部会有一个对应的存储单元被选中, 然后CPU就可以对该内存单元直接进行读写. 

SRAM内部会有一个类似74LS138译码器的器件, 用来将CPU管脚发出的一组信号转换为某一个被选中的存储单元. 不同的信号选中不同的存储单元, 如果我们把每组信号都看成一个地址, 那么被选中的`每个存储单元也就有了固定的地址`, 每个存储单元与CPU管脚发出的地址都一一对应. CPU管脚发出的地址信号一般被称为物理地址, 如图所示. 
- 通过地址访问存储单元
	- ![](assets/Pasted%20image%2020230512034323.png)

存储映射
- 存储映射: 为SRAM中的存储单元分配逻辑地址的过程
- 每个物理存储单元并没固定的地址
	- 现在的嵌入式系统中, CPU和外部设备一般是通过总线(如AMBA总线)相连的, CPU通过总线可以与多个设备相连, 多个设备共享总线, 包括DDR内存, SRAM等存储设备
- 每个物理存储单元的地址可以通过重映射改变
	- ![](assets/Pasted%20image%2020230512034625.png)

存储映射的实现

存储映射的具体实现与处理器相关, 不同的处理器可能有不同的实现方式. 
- 通过存储映射寄存器来实现: 通过配置要映射的起始地址, 结束地址或大小
- 通过设置BANK基地址来完成存储映射
- 通过位带区, 位带区别名来完成映射
- 无论采用何种映射方式, 存储器的映射一般都会在复位之前由CPU自动完成, 复位之后的CPU默认会从零地址开始执行代码, 这是所有处理器都要遵守的规则. 

## 嵌入式启动方式

采用存储映射的好处之一就是可以灵活设置嵌入式系统的启动方式. 

在一个嵌入式系统中, 很多人可能认为U-boot是系统上电运行的第一行代码, 然而事实并非如此, CPU上电后会首先运行固化在CPU芯片内部的一小段代码, 这片代码通常被称为ROMCODE, 如图所示. 
- ![](assets/Pasted%20image%2020230512035202.png)

- 这部分代码的主要功能就是初始化存储器接口, 建立存储映射. 它首先会根据CPU管脚或eFuse值来判断系统的启动方式: 从NOR Flash, NAND Flash启动还是从SD卡启动. 
- 如果我们将U-boot代码“烧写”在NOR Flash上, 设置系统从NOR Flash启动, 这段ROMCODE代码就会将NOR Flash映射到零地址, 然后系统复位, CPU默认从零地址取代码执行, 即从NOR Flash上开始执行U-boot指令. 
- 如果系统从NAND Flash或SD卡启动, 通过上面的学习我们已经知道, 除了SRAM和NOR Flash支持随机读写, 可以直接运行代码, 其他Flash设备是不支持代码直接运行的, 因此我们只能将这些代码从NAND Flash或SD卡复制到内存执行. 
- 因为此时DDR SDRAM内存还没有被初始化, 所以我们一般会先将NAND Flash或SD卡中的一部分代码(通常为前4KB)复制到芯片内部集成的SRAM中去执行, 然后在这4KB代码中完成各种初始化, 代码复制, 重定位等工作, 最后PC指针才会跳到DDR SDRAM内存中去运行. 
	- NOR启动流程
		- ![](assets/Pasted%20image%2020230512035709.png)
	- NAND启动流程
		- ![](assets/Pasted%20image%2020230512035737.png)
	- SD卡启动流程
		- ![](assets/Pasted%20image%2020230512035817.png)

# 存储抽象: 文件系统

存储器件一般分两种: 机械硬盘和固态硬盘, 机械硬盘由多个盘片组成, 每个盘片分为不同的扇区, 各种数据分别存储在这些扇区上, 数据的读写通过磁头的移动寻道和盘片的转动来完成. 
因为磁头和磁道的距离非常接近, 因此普通机械硬盘抗震能力较差. 

SSD固态硬盘和闪存存储底层都使用Flash存储芯片, 不需要磁头寻道, 读写速度快, 无噪声, 发热小, 支持低功耗待机. 目前常见的存储芯片有NAND Flash, eMMC等. 

一个NAND Flash存储芯片, 由不同的block组成, 每个block又分为很多页, 每一页的大小为512字节, 1024字节, 4096字节甚至更大, 数据以二进制格式存储在每个页上. 
- ![](assets/Pasted%20image%2020230512040445.png)

一个磁盘由磁柱, 磁道和扇面组成, 数据存储在不同的扇区上, 磁头可以在不断旋转的磁道上来回移动, 读写不同扇区上的数据. 
- ![](assets/Pasted%20image%2020230512040457.png)

从用户层面上看, 操作的对象是一个个文件, 而不是存储在底层硬件设备上的一串串二进制数据. 从底层物理存储设备上的二进制数据到不同目录下的具体的文件名, 这个转换过程就是由文件系统完成的. 

## 什么是文件系统

文件系统其实就是一个存储管理程序, 通过对不同物理存储设备进行抽象和管理, 呈现给用户的操作接口是人类更容易接受的目录和文件的形式. 

文件系统会对存储设备进行抽象封装, 向用户提供一组目录和文件操作的API. 

当用户使用这些API新建一个文件时, 文件系统就会建立该文件到实际物理存储之间的一个映射, 用户不必再深入底层硬件细节去读写数据, 直接通过文件名即可直接访问, 简单方便. 

如计算机的F盘上有一部《舌尖上的中国》视频文件, 它实际存储在硬盘上某片连续的物理扇区上, 文件系统帮我们在文件名和它具体的存储位置之间建立了映射关系. 当我们播放这个文件时, 视频播放器不必关心这个文件到底存储在哪里, 直接通过文件系统提供的open()/read()/write()接口, 通过文件名直接访问就可以了, 如图所示. 
- ![](assets/Pasted%20image%2020230512040516.png)

一个嵌入式系统也是如此, 假如在Linux目录下有一个E01.mkv视频文件, 其真正的存储位置可能位于NAND Flash芯片上某个block的连续页内. 当播放器应用程序访问这个文件时, 也不必关心这个视频文件在NAND Flash上的具体存储位置, 直接通过文件名读写就可以了, 文件系统已经帮我们建立了映射关系, 并提供了各种读写, 打开, 关闭, 位置定位等操作接口, 如图所示. 
- ![](assets/Pasted%20image%2020230512040650.png)

文件系统格式化
- 什么是格式化?
	- 对存储设备的抽象
		- 地址管理: 文件/目录与磁盘存储地址的映射
		- 权限管理: 文件读写, 安全保护
		- 统一接口: 文件系统的相关系统调用

一个刚出厂的存储设备, 如U盘, 里面其实就是一个一个存储单元阵列. 在使用之前, 一般需要先格式化, 格式化时需要`选择一种文件系统类型`. 

所谓格式化, 其实就是`让文件系统去管理这块存储空间`, 文件系统可能会把这块原始存储空间像耕地一样划分为大小相同的块, 建立文件名, 目录名到实际物理存储地址的映射关系, 并将这些映射关系存储在某块物理存储单元内, 如图所示. 
- ![](assets/Pasted%20image%2020230512041242.png)

用文件系统的专业术语来描述就是: 当我们格式化一个U盘时, 文件系统会将U盘的物理存储单元划分为大小相等的逻辑块——block, block是文件系统存储数据的基本管理单元. 文件系统将U盘的存储空间分为两部分: 纯数据区(data)和元数据区(meta data). 

如图所示, 纯数据区是文件真正的数据存储区, 而元数据区则用来存储文件的相关属性: 该文件在磁盘中的存储位置, 文件的长度, 时间戳, 读写权限, 所属组, 链接数等文件信息. 
- ![](assets/Pasted%20image%2020230512041412.png)
	- 文件系统中的每一个文件都用一个inode结构体来描述, 用来存储文件的元数据信息. 每个inode都有固定的编号和单独的存储空间, 每个inode都为128或256字节大小. Linux系统根据元数据区的inode来查找文件对应的物理存储位置. 
	- 当用户通过指定的路径文件名去读写一个文件时, 文件系统根据目录项中文件名和inode编号之间的对应关系, 会到存储在元数据区的索引节点表中, 找到该文件对应的inode节点. 根据这个inode节点信息, 就可以找到该文件在磁盘上的具体存储位置. 

## 文件系统的挂载

应用程序通过文件系统提供的API读写文件时, 通常是以“路径+文件名”的形式进行访问的. 如果我们想访问某个存储设备, 一般需要`先将该存储设备挂载(mount)到文件系统的某个目录上`, 然后对该挂载目录的读写操作就相当于对该存储设备的读写操作. 

将一个存储设备mount到一个目录上的本质, 其实就是改变该目录到具体物理存储的映射关系, 让该存储设备与要挂载的某个目录建立关联, 加入全局文件系统目录树中. 

如我们将一个U盘mount到Linux系统的mnt目录下, 然后在/mnt目录下创建一个文件, 接着将U盘从/mnt目录卸载, 此时你再到/mnt目录下看看, 你会发现空空如也. 

文件系统的挂载
- 文件系统要先挂载到某一个目录, 然后才能使用
- mount的本质: 改变映射关系

这是因为当我们使用mount命令将U盘设备挂载到/mnt目录的时候, mnt目录就和U盘存储设备建立了映射关系, 文件系统会把我们对/mnt目录的读写操作转换为对U盘的读写操作. 当我们卸载U盘的挂载时, mnt目录会重新映射到原来的存储空间, 此时你再到/mnt目录下去看, 什么都没有, 如图所示. 
- 文件系统挂载时的数据结构关联
	- ![](assets/Pasted%20image%2020230512041808.png)

在Linux环境下, 当我们使用mount命令去挂载一个块存储设备时, 在操作系统内核层面会做很多事情: 首先每个块存储设备在挂载之前得把自己格式化一遍, 然后以子文件系统的身份挂载到父文件系统的某一个目录下. 对于每个挂载的文件系统, Linux内核都会创建一个vfsmount和super_block对象, 该对象描述了文件系统挂载的所有信息, 父文件系统的挂载点vfsmount->mnt_mountpoint=/mnt和子文件系统的根目录vfsmount->mnt_root=superblock->s_root就可以通过这两个对象建立关联. 

文件系统的挂载在Linux内核中的实现远比上图所示的复杂, 还会涉及目录, 路径解析, 哈希算法等操作. 为了让初学者对文件系统的挂载有一个感性的认识, 我们可以简单点理解, 你可以把目录看成一个指针, 它可以指向不同的物理存储设备, 你可以将多个设备挂载到同一个目录下, 但该目录只指向最后一次挂载的存储设备, 当挂载的设备卸载时, 该指针会重新指向原来的物理存储空间. 

## 根文件系统

- 根目录“/”
	- Linux内核初始化后, 创建的一个根目录
	- 接着会mount第一个文件系统: 根文件系统
	- 其它分区, 磁盘, SD先mount到RootFS上, 然后通过文件接口访问各个不同的存储设备
- 根文件系统
	- Linux内核运行所需要的一些目录: 挂载, 命令, 库
	- 启动脚本, 配置文件, 服务程序
	- 二进制可执行程序
	- 库, 头文件

在Linux环境下, 一个根文件系统会包含Linux运行所需要的完整目录和相关的启动脚本, 配置文件, 库, 头文件等. 它经常会包含以下目录. 
- bin, /sbin: 存放Linux常用的命令, 以二进制可执行文件形式存储在该目录下. 
-  /lib: 用来存放Linux常用的一些库, 如C标准库. 
-  /include: 头文件的存放目录. 
-  /etc: 用来存放系统配置文件, 启动脚本. 
-  /mnt: 常用来作为挂载目录. 

# 内存与外部设备

## 内存与外存

计算机的存储设备如果按照存取速度进行排列, 可以分为以下几类: 寄存器, 缓存, 内存, 外存. 

寄存器和Cache的物理电路实现其实都是SRAM, SRAM读写速度快, 但是电路实现复杂, 物理成本比较高, 占用的芯片面积比较大, 功耗高, 因此在CPU内部的容量一般不是很大. 

内存一般又称为主存, 是CPU可以直接寻址的存储空间, 存取速度快, 常见的内存包括RAM, ROM, NOR Flash等. 

外存一般又称为辅存, 是除CPU缓存和内存外的存储器, 包括磁盘, NAND Flash, SD卡, EEPROM等. 

## 外部设备

- 什么是外设?
	- 从程序运行的角度看, 和内存对应的是外部设备, 简称外设. 
	- 计算机系统中输入, 输出设备的统称(包括外存)
	- 外设: 鼠标, 键盘, 显卡, 声卡, 打印机, 磁盘
	- 外设接口: UART, USB, I2C, GPIO, I2S, Ethernet, AD/DA

外设控制器
- 设备控制: 设备的打开, 关闭, 运行都可以通过配置相关寄存器来完成
- 协议控制: USB, I2C, UART, I2S, 控制器在电气层会实现各种通信协议
- 数据转换: 序列流, 字节流. 
- 数据缓冲: 缓冲区, FIFO, 发送接收数据的缓冲区. 
	- ![](assets/Pasted%20image%2020230512043133.png)
	- 缓存
		- ![](assets/Pasted%20image%2020230512043522.png)

以USB控制器为例, CPU通过控制器与外部的USB设备进行通信时, 就不需要自己关心底层通信协议的实现细节了, 控制器内部已经实现好了, 只要配置好相关寄存器, 就可以很轻松地与外界USB设备进行数据传输了. 

CPU与外设通信

CPU与外部设备进行通信, 常见的有3种方式: 轮询, 中断和DMA. 轮询和中断我们已经很熟悉了, 以中断为例, 我们看一看CPU与外部设备进行通信时的数据流. 

外部设备控制器通过协议控制与外部设备进行数据传输, 接收的数据会暂时保存到控制器内部的FIFO里. 当FIFO里的数据已满或达到一个设定阈值后就会产生一个中断, CPU检测到中断后就会进入相关的中断处理函数中执行. 在中断处理函数中, CPU会读取FIFO里的数据到寄存器, 然后将寄存器中的数据保存到内存中的某块区域. 

发送数据的流程则正好相反, CPU首先会到内存的某块区域读取数据到寄存器, 然后将寄存器中的数据填充到FIFO. 填充完毕后, 启动控制器开始发送, 当控制器发送数据完成后会产生一个中断, CPU进入中断处理函数, 继续填充FIFO, 直到整个数据发送任务完成. 

无论是数据流的输入还是输出, CPU都参与了其中, 在内存和外部设备之间担任了“中转站”的角色. 如果我们将这个“中转站”的角色交给其他模块负责, 那么就可以节省大量的CPU资源, 从而可以进一步提高系统效率. 

在一个CPU内部, DMA模块其实就是干这个的, 它会代替CPU充当“中转站”的角色, 无论是数据的输入还是数据的输出, 我们只要在DMA控制器中设置好数据传输的起始地址, 目的地址, 传输数据大小, DMA就会自动开始工作. DMA内部也有缓存, 它会将内存的数据先搬到DMA, 然后通过DMA发送出去, 就不需要CPU的参与了. 数据传输任务完成以后, DMA产生一个中断, 告诉CPU数据传输已经完成就可以了. 

## I/O端口与I/O内存

CPU与外设通信
- 51 跟 arm 配置寄存器
	- ![](assets/Pasted%20image%2020230512043929.png)

CPU可以通过寄存器配置来控制外部设备控制器与外部设备进行通信. 在一个外部设备控制器中, 通常会包含各种控制寄存器, 状态寄存器, FIFO, 缓冲区等. CPU可以通过地址直接操作内存, 那么CPU也可以通过地址去直接读写这些寄存器吗? 

CPU能不能像读写内存那样, 通过地址直接读写这些寄存器呢?那就要看这些外部设备寄存器的编址方式了, 我们一般称这些`外部设备控制器的寄存器`为`I/O端口`, 每一个寄存器对应一个端口. 给这些I/O端口分配地址, 一般有两种方式: 独立编址和统一编址. 
- 独立编址
	- 端口独立编址: 0~0xFFFF
	- 该地址与内存地址没有任何关系
		- CPU不能像读写内存那样直接对这些端口进行读写
	- 专有IN/OUT命令读写寄存器
- 统一编址
	- ARM架构的处理器一般会将外部设备控制器的这些寄存器, 缓冲区, FIFO和内存统一编址
	- 外部设备控制器的寄存器和内存一起共享地址空间, 因此也被称为I/O内存
	- CPU可以按照内存读写的方式, 直接读写这些寄存器来管理和操作外部设备
	- 寄存器地址访问权限管理
		- ![](assets/Pasted%20image%2020230512044352.png)

# 寄存器操作

在ARM处理器中, 我们可以像操作内存一样对寄存器进行读写, 进而可以配置控制器与外部设备进行通信. 在一个32位的处理器中, 一个寄存器位宽为32bit, 不同的位可能代表不同的控制信息或状态信息, 通常我们使用位运算来操作这些寄存器. 

## 位运算应用

位运算在实际编程中用到的地方不是很多, 除了一些特殊的算法实现需要, 主要还是用在嵌入式中, 用来操作寄存器. 

位运算符
- 基本运算符
	- 取反: ~
	- 左移: <<
	- 右移: >>
	- 与 : &
	- 异或: ^
	- 或 : |
		- ![](assets/Pasted%20image%2020230512044922.png)

在一些算法的实现和特殊应用场合, 使用位运算不仅会简化实现, 还会大大提升程序的运行效率. 例如, 如果我们想让一个数据的高低位互换, 则直接使用移位操作就可以实现. 
```c
#define swap_endian_u16(A) \
 (((A & 0xFF00) >> 8) | ((A & 0x00FF) << 8))

#define swap_endian_u32(A) \
 (((A & 0xFF000000) >> 24) | ((A & 0x00FF0000) >> 8) \
 | ((A & 0X0000FF00) << 8) | ((A & 0x000000FF) << 24))
```

在Linux驱动或底层BSP代码中, 我们有时候会看到类似`mask&(mask-1)`的程序语句, 这个表达式可以用来判断一个数是否为2的整数次幂. 
```c
mask&(mask-1) == 0 是2的整数次幂
```
一个数对另一个数做2次异或运算, 还等于其本身. 利用这个特性, 我们可以实现数据的加密. 

利用异或的这种特性, 我们还可以实现一个函数, 不需要借助第三方变量, 实现两个变量无参交换. 
```c
void swap(int *a ,  int *b)
{
	*a = *a^*b; 
	*b = *a^*b; 
	*a = *a^*b; 
}
```

## 操作寄存器

位运算在一些特殊的应用场合也会用到, 如位图, 操作系统的调度实现等, 但其主要功能还是用来操作寄存器. 在一个32bit的寄存器中, 下图所示的USB控制器中的寄存器, 不同的位可能代表不同的控制位, 状态位, 通过位运算可以对指定的位进行置一或清零操作. 

查看datasheet
- 寄存器地址  寄存器说明
	- ![](assets/Pasted%20image%2020230512045738.png)

以一个int型数据为例, 如果我们想将一个32bit的数据0xFFFF0000低4位置一, 则可以将该数据和位掩码0x0F直接进行`或运算`: 
- ![](assets/Pasted%20image%2020230512050011.png)
如果我们要操作的位不是连续的, 将位掩码转换为十六进制比较麻烦, 则可能还需要手动计算. 为了程序的方便编写和可读性, 位掩码可以通过各个比特位进行或运算来生成. 同样的道理, 如果我们想清除某些指定位, 如将0xFFFFFFFF的bit4～bit7清零, 可以让该数与位掩码0xFFFF00FF做与运算. 
- ![](assets/Pasted%20image%2020230512050019.png)

为了编程方便, 我们同样可以将位掩码0xFFFFFF0F用各个比特位的掩码或运算组合表示, 但是0xFFFFFF0F中bit1的个数较多, 用各个比特位或运算比较麻烦, 整个或表达式就变得很长, 而且我们要清除的是bit4～bit7, 直接将位掩码0xFFFFFF0F展开, 并不能直观表示我们要清除的是哪些比特位. 因此, 我们可以稍做改变, 将位掩码0xFFFFFF0F使用~(0x000000F0)表示, 而将0x000000F0二进制展开, 就可以直观地看到我们要清除的比特位信息了. 

为了更加直观地表示这些比特位, 我们还可以定义一些宏来表示各个比特位, 这样就省去了移位的麻烦. 
```c#
#define BIT_0 0x1
#define BIT_1 0x1<<1
#define BIT_2 0x1<<2
#define BIT_3 0x1<<3
#define BIT_5 0x1<<5
#define BIT_6 0x1<<6
#define BIT_9 0x1<<9
#define BIT_12 0x1<<12
#define BIT_23 0x1<<23

int main1(void)
{
	printf("%X\n", 0xF0|(BIT_0|BIT_1|BIT_2|BIT_3));  
	printf("%X\n", 0xFF&0xFFFFFFF0); 
	printf("%X\n", 0xFF& ~(BIT_0|BIT_1|BIT_2|BIT_3)); 
	return 0; 
} 
int main(void)
{
	int a = 0x00; 
	printf("%X\n", a); 
	a |= (BIT_0|BIT_5|BIT_9); 
	printf("%X\n", a); 
	a &= ~(BIT_0|BIT_5|BIT_9); 
	printf("%X\n", a); 	
	return 0; 
}
```

在上面的程序中, 各个比特位通过宏的封装, 再使用这些宏去置位或清零某个指定位, 就变得更加直观和简单了. 我们可以根据寄存器的配置需求, 灵活地对指定位进行置位和清零操作, 宏的使用让程序的可读性大大提高, 让程序更易管理和维护. 

## 位域

读写寄存器除了使用“位掩码+位运算”的组合方式, 还有另外一种比较直接的方法: 使用位域直接操作寄存器. 

位域的应用
- 信息的压缩存储, 节省存储单元
- 读写方式方便, 可读性强
- 操作系统内核, 驱动源码: tcphdr

位域一般和结构体类型结合使用: 虽然结构体的成员由位域构成, 但结构体的本质不变, 还是一个结构体. 我们同样可以使用该结构体类型去定义一个变量, 唯一不同的是, 结构体内各成员的存储是按比特位分配的. 
- ![](assets/Pasted%20image%2020230512050400.png)

在一个寄存器中, 几个连续的比特位可以组成一个位域, 用来表示寄存器的控制位或状态位. 我们通过定义一个结构体, 可以使用不同的位域来表示这些不同的控制位或状态位. 

如上面的程序所示, USB寄存器的bit5～bit7位用来表示USB的工作模式: mode, 我们在一个结构体内为它分配3bit的存储空间. 通过这种位分配方式可以将一些信息压缩存储, 既节省了内存空间, 还可以通过位域进行直接读写, 在方便程序编写的同时, 程序的可读性也大大增强. 
- ![](assets/Pasted%20image%2020230512050607.png)

位域不仅可以和结构体结合使用, 还可以和联合体结合使用. 位域的使用方法和联合体的使用规则是一样的, 因为使用位域组合联合类型定义的变量本质上还是一个联合变量. 
```c
union spsr{
	unsigned short mode: 3; 
	unsigned short ep: 4; 
	unsigned short en: 1; 
}; 
int main()
{
	union spsr reg2; 
	memset(&reg2, 0, sizeof(reg2)); 
	reg2.mode = 3; 
	printf("reg2: %x\n", reg2); 
	return 0; 
}
```

在一些芯片控制器的寄存器中, 有些位可能未被使用, 还处于reserved状态, 我们在定义结构体时可以使用一个匿名位域来表示. 
```c
struct register_usb2{
	unsigned short en: 1; 
	unsigned short ep: 4; 
	unsigned short : 3;  
	unsigned short mode: 6; 
}; 
```

C语言允许在结构体中使用匿名位域. 如上面的register_usb2结构体, 如果USB寄存器的bit1～bit3位暂时未被使用, 为了不影响后面其他位域的地址分配, 我们可以使用一个匿名位域填充. 

位域在C语言编程中比较“非主流”, 包含位域操作的程序代码往往给初学者, 甚至有多年编程经验的程序员造成一定的阅读障碍. 在以后的编程中, 从代码的可读性和可维护性考虑, 建议大家还是尽量使用“位掩码+位运算”的组合比较妥当. 

# 内存管理单元MMU

Linux内存管理是嵌入式系统中比较难理解的一个知识点, 也是非常重要的一个知识点. 在嵌入式开发中, 无论底层还是上层, 都会经常和内存打交道, 如内存映射, 共享内存, copy_to_user, 
copy_from_user. 

内存管理单元
- 地址转换
- 权限管理
- 交换分区

## 地址转换

内存管理单元MMU集成在CPU内部, 主要用来将虚拟地址转换为物理地址. CPU有了这个功能, 各个App的编译就变得简单了. 每个App编译时都以虚拟地址为链接地址, 甚至使用相同的链接地址都可以. 

当各个App运行时, CPU会通过MMU将相同的虚拟地址映射到不同的物理地址, 各个App都有各自的物理内存空间, 互不影响各自的运行. 

MMU会根据每个进程的地址转换表将相同的虚拟地址转换为不同的物理地址. 当PC指针执行app1时, 到0x10000虚拟地址处去取指令, 经过MMU地址转换后, 会到实际物理内存的0x30001000处取指令. 当PC指针执行app2时, 同样会到0x10000地址去取指令, 经过MMU地址转换后, 会到实际物理内存的0x30005000处取指令. 
- ![](assets/Pasted%20image%2020230512051848.png)

对于每一个应用程序来讲, 每一个虚拟地址通过地址转换表, 都可以与实际的物理内存地址一一对应, 不同的应用程序有不同的地址转换表, 相同的虚拟地址会映射到不同的物理地址上. 

上面的地址转换表虽然解决了虚拟地址到物理地址的转换问题, 但是很浪费内存: app1的大小为4KB, 那么至少需要4KB大小的空间来存储这个地址转换表信息; app2的大小为8KB, 那么至少需要8KB大小的空间来存储app2的地址转换表. 为了解决内存浪费的问题, 我们需要对地址转换做一些改进. 
- 页帧号+页内偏移
	- ![](assets/Pasted%20image%2020230512051957.png)

我们不再对每个地址都一一映射了, 这样太浪费内存. 我们可以将内存分隔成4KB大小相同的内存单元, 每个内存单元都被称为页或页帧. 我们以页为单位进行映射, 地址转换表中只保存每个页的虚拟起始地址到物理起始地址的转换关系. 通过这种设计, 你会发现地址转换表的空间就由原来的4KB减少为1字节. 这种按页映射的设计大大节省了内存空间, 此时的地址转换表一般也被称为`页表`. 
- ![](assets/Pasted%20image%2020230512052145.png)

一个页表中有很多页表项, 每一个页表项里只有每个页的虚拟起始地址到物理起始地址的转换信息. 那么对于一个具体存储单元的虚拟地址, CPU是如何将其转换为物理地址的呢?

一般CPU会把这个虚拟地址分解成页帧号+页内偏移的形式. 对于同一个虚拟地址
0x10004, 可以分解为0x10+0x004的形式, 0x10是页帧号, 0x004是页内偏移(因为是以4KB为单位划分页的, 所以使用低12位表示4KB范围的页内偏移). 

MMU根据页表中保存的页的转换信息, 将这个虚拟页的页帧号转换成物理页的页帧号0x30005, 这个物理页帧号0x30005再与页内偏移0x004组装, 就构成了物理地址0x30005004. 此时MMU就完成了虚拟地址到物理地址的转换, 可以直接到实际物理内存的0x30005004地址处去取指令了. 

从虚拟地址到物理地址的整个转换过程实际上是由硬件和软件协作完成的. 

CPU内部集成的MMU器件, 通过页表内每一个页表项的转换关系, 将虚拟地址转换为不同的物理地址. 而页表则是由操作系统维护的, 由Linux内存管理子系统负责管理和维护, 当地址完成转换后, 会同步更新到用户空间的每一个进程内. 

MMU每次地址转换, 会首先从内存中读取页表, 根据页表内的地址转换信息将一个个虚拟地址转换为物理地址. 为了提高转换效率, 在CPU内部一般会集成一个缓存——TLB, 用来缓存部分页表. 

当MMU地址转换时, 会首先根据虚拟地址到TLB这个缓存里去看看里面有没有对应地址的转换信息, 如果有, 就不需要到内存中去取了; 如果没有, 则MMU再到内存中去取, 同时TLB会重新缓存这个新地址附近的转换信息, 以供MMU下次转换时使用. 通过TLB的缓存设计, 可以在一定程度上提升MMU的地址转换效率. 

## 权限管理

- 页表项
	- 地址转换信息
	- 访问权限

地址转换是MMU的基本功能, 除此之外, MMU和页表还可以对不同的内存区域设置不同的权限, 防止内存被践踏, 从而保障系统的安全运行. 

![](assets/Pasted%20image%2020230512052756.png)

![](assets/Pasted%20image%2020230512052800.png)

一个页表有若干个页表项构成, 每个页表项不仅包含地址转换信息, 还包含每一个进程中不同内存区域的访问权限信息. 通过这种设计, 我们就可以对不同用户进程映射到实际物理内存的地址空间进行权限管理. 

- 交换分区
	- ![](assets/Pasted%20image%2020230512052847.png)
- 备份到磁盘
	- ![](assets/Pasted%20image%2020230512052926.png)
- 重新载入内存
	- ![](assets/Pasted%20image%2020230512052935.png)

# 进程, 线程和协程

在没有MMU的RTOS环境下，因为没有内存管理，整个物理内存空间对于程序来说都是一马平川：一个内存中的全局变量，所有的任务都有权限去访问和修改它。

在RTOS多任务环境下，为了全局变量的安全访问，我们一般将函数分为可重入函数和不可重入函数。

一个函数如果使用了全局变量，就变得不可重入了；如果多个任务都去调用这个函数，可能就会出现问题。因此我们在多任务编程中尽量不要调用不可重入函数。

但是在实际编程中，一个函数不可能完全跟全局变量这些共享资源划清界限。对于一个不可重入函数来说，如果我们在它访问全局变量的时候，通过锁、关中断等机制实现互斥访问，那么这个不可重入函数也就变得安全了。此时，我们就说这个函数是线程安全的。
- ![](assets/Pasted%20image%2020230512053800.png)

在一个多任务环境下，一个可重入函数肯定是线程安全的，一个不可重入函数如果对临界资源实现了互斥访问，那么它就变成了线程安全的。

我们在进行多任务编程时，在调用一个函数之前，很有必要先了解一下这个函数是否是线程安全的。在Linux环境下，我们可以使用man命令来查看。
- ![](assets/Pasted%20image%2020230512053840.png)

对于用户申请和释放的内存，glibc使用一个全局链表管理和维护，malloc()函数跟这个全局链表产生了关联，因此也变得不可重入了，但是如果malloc()函数在访问这些全局的资源时，通过临界区实现互斥访问，这个函数也就变得线程安全了。因此在glibc库中，虽然malloc()函数是不可重入函数，但它是线程安全的：无论是多进程编程，还是多线程编程，不用担心，都可以放心大胆地调用它。

## 进程

在一个无MMU的多任务环境下，一般是不区分进程和线程的：我们都把它看作一个任务。
但是在Linux环境下，进程和线程则是两个不同的概念。

在Linux环境下运行一个程序，操作系统会把这个程序包装成进程的形式，每一个进程都使用task_struct结构体来描述，所有的结构体链成一个链表，参与操作系统的统一调度和运行。

每一个Linux进程都有其单独的4GB虚拟地址空间。Linux引入了内存管理机制，使用页表保存每个进程中虚拟地址和物理地址的对应关系，通过MMU地址转换，每一个进程相同的虚拟地址空间都会被映射到不同的物理内存，每一个进程在物理内存空间都是相互独立和隔离的。

在Linux环境下，因为每个进程在物理内存上都是相互隔离的，所以我们在多进程编程时，无论一个函数是否是可重入的，无论这个函数是否是线程安全的，我们在一个进程中都可以调用它们。
- ![](assets/Pasted%20image%2020230512054056.png)

不同的进程之间如果需要相互通信，该怎么办呢？因为不同的进程在物理内存上是相互隔离的，所以我们需要借助第三方工具来完成进程间的通信。

在每一个进程的4GB虚拟空间中，除了3GB的用户空间是各个进程独享的，还有1GB的内核空间是所有进程共享的，不同的进程可以通过在内核空间中开辟一片内存进行通信。
- ![](assets/Pasted%20image%2020230512054126.png)

不同的进程虽然在物理内存上是相互独立的，但是磁盘是所有进程共享的，它们之间通过磁盘文件相互传输数据，也可以达到进程间通信的目的。

除此之外，两个进程还可以通过共享内存，映射到同一片物理内存直接进行通信，效率会更高。

Linux提供了各种工具来支持不同进程之间的通信，每一种工具都有自己的应用场合。
- 无名管道：只能用于具有亲缘关系的进程之间的通信。
- 有名管道：任意两进程间通信
- 信号量：进程间同步，包括system V信号量、POSIX信号量。
- 消息队列：数据传输，包括system V消息队列、POSIX消息队列
- 共享内存：数据传输，包括system V共享内存、POSIX共享内存
- 信号：主要用于进程间的异步通信。
- Linux新增API：signalfd、timerfd、eventfd。
- Socket：套接字缓冲区，不同主机不同进程之间的通信。
- D-BUS：主要用于桌面应用程序之间的通信。

## 线程

一个程序运行时，进程是Linux分配资源的基本单元：系统默认操作是先fork一个子进程，分配物理内存，然后将要执行的可执行文件加载到内存。每个进程都是相互独立的，不同的进程要借助第三方工具才能进行通信，不同的进程在切换运行时，CPU要不停地保存现场、恢复现场，进程上下切换的开销很大。

![](assets/Pasted%20image%2020230512054351.png)

为了减少进程的开销，线程这时候就闪亮登场了。

在一个进程中可能存在多个线程，多个线程共享进程中的代码段、数据段、地址空间、打开文件、信号处理程序等资源。每个线程都有自己单独的资源，如程序计数器、寄存器上下文及各自的栈空间。

正是因为多个线程共享进程的资源，当不同线程对这些共享资源进行访问时，又要涉及共享资源的安全访问和线程间的同步问题了。一般我们可以通过互斥锁、条件锁和读写锁等同步机制来实现不同线程对共享资源的安全访问。

在多线程编程中，我们同样可以通过互斥锁来实现对共享资源的互斥访问。在pthread多线程库中，与互斥锁相关的API函数如下所示。
- ![](assets/Pasted%20image%2020230512054541.png)
- ![](assets/Pasted%20image%2020230512054550.png)

不同的线程虽然可以通过加锁、解锁这一对操作来实现线程间同步，但不停地加锁和解锁操作、不停地查询满足条件也会带来很大的开销。当程序调用加锁函数时，操作系统会从用户态切换到内核态，并阻塞在内核态；当程序调用解锁函数时，操作系统同样会经历从用户态到内核态，再从内核态到用户态的转换。

我们可以使用条件变量和互斥锁搭配使用，来减少不断加锁、解锁带来的开销。将互斥锁和条件变量绑定，允许线程阻塞，等待条件满足的信号，然后使用广播去唤醒所有绑定到该条件变量的线程，就可以省去不断加锁和解锁的开销。与条件变量相关的API函数如下。
- ![](assets/Pasted%20image%2020230512054632.png)

互斥锁在同一时刻只允许一个线程进行读或写，而使用读写锁，可以允许多个线程同时进行读操作。虽然多个线程可以同时读一个共享资源，但同一时刻只允许一个线程进行写操作，写的时候会阻塞其他线程（包括读线程），写线程的优先级高于读线程。在pthread线程库中，与读写锁相关的API函数如下。
- ![](assets/Pasted%20image%2020230512054700.png)

## 线程池

一个进程内的多个线程，虽然可以共享进程的很多资源，如代码段、数据段、打开的文件等，但也有各自的上下文环境，如寄存器状态、栈、PC指针等。
- ![](assets/Pasted%20image%2020230512054731.png)

在Linux环境下，进程是资源分配的基本单元，而线程则是程序执行和调度的最小单元。线程的开销，除了不断加锁和解锁、线程上下文切换带来的开销，还包括系统调用的开销，如线程不断地创建和销毁，在一些频繁使用线程的场合，开销也会线性上升。

为了减少线程不断创建和销毁带来的开销，我们可以实现一个线程池。预先在线程池中创建一些线程，没有工作任务时，线程阻塞在池中；有任务时，则通过管理线程将任务分配到指定的线程执行。

线程池的实现原理
- ![](assets/Pasted%20image%2020230512054809.png)

一个线程池由管理线程、工作线程和任务接口构成。管理线程用来创建并管理工作线程，将用户创建的不同任务分配给不同的工作线程执行。工作线程是线程池中执行实际任务的线程，无任务时，这些工作线程则阻塞在线程池中。线程池一般还会引出任务接口供用户调用，用户通过这个任务接口，可以创建不同的任务，并最终分配到不同的工作线程中执行。

线程池技术省去了线程不断创建和销毁带来的系统开销，在一些频繁使用线程、调用线程的场合，这种设计方案很划算。线程池中的线程数量甚至还可以根据任务的多少来动态删减，在内存开销和性能开销之间达到一个很好的平衡。

## 协程

在一些高并发、高访问量的服务器领域，使用线程池技术虽然可以在一定程度上减少线程不断创建和销毁带来的开销，但面对大量的、频繁的互联网并发请求，线程的上下文切换和不断加锁解锁带来的开销，越来越成为提升服务器性能的瓶颈。

协程就是将对共享资源的访问交给程序本身维护和控制，不再使用锁对共享资源互斥访问，无调度开销，执行效率会更高。协程一般适用在彼此熟悉的合作式多任务中，上下文切换成本低，更适合高并发请求的应用场景。